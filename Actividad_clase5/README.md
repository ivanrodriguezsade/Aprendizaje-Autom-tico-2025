 Actividad - Clase 5: Comparaci贸n de Clasificadores (rbol de Decisi贸n vs. K-NN)

1. Introducci贸n y contexto del problema

El objetivo de esta actividad es evaluar y comparar la precisi贸n de dos algoritmos fundamentales de clasificaci贸n: el rbol de Decisi贸n (Decision Tree) y K-Vecinos M谩s Cercanos (K-NN).

Hemos utilizado el conjunto de datos de C谩ncer de Mama de Wisconsin (load_breast_cancer) de la librer铆a scikit-learn, un problema de clasificaci贸n binaria (Diagn贸stico: Benigno o Maligno).

Metodolog铆a

   Datos: Dataset de C谩ncer de Mama de Wisconsin (569 instancias, 30 caracter铆sticas).

   Divisi贸n: 70% para entrenamiento, 30% para prueba.

   Preprocesamiento: Se aplic贸 escalado de caracter铆sticas (StandardScaler) exclusivamente al modelo K-NN, ya que este algoritmo se basa en la distancia y es altamente sensible a la escala de las variables de entrada. El rbol de Decisi贸n utiliz贸 los datos sin escalar.

   Par谩metros:
        rbol de Decisi贸n: Profundidad M谩xima (max_depth) = 5.
        K-NN: N煤mero de Vecinos (n_neighbors) = 5.

2. Resultados Cuantitativos y M茅tricas

A continuaci贸n, se presenta la comparaci贸n de rendimiento en el conjunto de prueba, utilizando la Precisi贸n y el Reporte de Clasificaci贸n (que incluye el Recall y el F1-Score) para una evaluaci贸n completa.

Comparaci贸n general de Precisi贸n

| Algoritmo | Precisi贸n (*Accuracy*) | Recall (Maligno - Clase 1) | F1-Score (Maligno - Clase 1) |
| :---: | :---: | :---: | :---: |
| **rbol de Decisi贸n** | [**_0.9532_**] | [**_0.96_**] | [**_0.96_**] |
| **K-NN (k=5)** | [**_0.96_**] | [**_0.97_**] | [**_0.97_**] |

(El F1-Score es la m茅trica m谩s robusta en este caso, ya que equilibra la capacidad de detecci贸n con la predictividad.)

Matrices de Confusi贸n

### rbol de Decisi贸n
![Matriz de Confusi贸n para el rbol de Decisi贸n](matriz_dt.png)

### K-NN
![Matriz de Confusi贸n para K-NN](matriz_k-nn.png)

3. Visualizaciones Clave

A. Visualizaci贸n del rbol de Decisi贸n

El gr谩fico muestra las reglas aprendidas por el modelo. La ruta desde la ra铆z hasta una hoja representa la secuencia de decisiones tomadas para clasificar un tumor como Benigno o Maligno.

### Visualizaci贸n del rbol de Decisi贸n
![ver rbol de Decisi贸n](arbol.png)

B. Frontera de Decisi贸n de K-NN (2D Ilustrativo)

Este gr谩fico ilustra c贸mo K-NN divide el espacio de datos, bas谩ndose en la proximidad. La frontera es irregular y no lineal, reflejando que la clasificaci贸n es determinada por la mayor铆a de los 5 vecinos m谩s cercanos.

Se utiliz贸 una proyecci贸n 2D (con las primeras dos caracter铆sticas escaladas) solo con fines ilustrativos, ya que el modelo real opera en 30 dimensiones.

### Frontera de Decisi贸n
![Frontera de Decisi贸n para k-nn](frontera_de_decision_k-nn.png)

4. An谩lisis Comparativo

| Aspecto | rbol de Decisi贸n (DT) | K-NN (K=5) |
| :--- | :--- | :--- |
| **Requerimiento de Datos** | No afectado por el escalado de caracter铆sticas. | **Depende totalmente del escalado** (necesita `StandardScaler`). |
| **Interpretabilidad** | **Alta ("Caja Blanca"):** Las reglas son visibles y f谩ciles de explicar (ej., umbrales). | **Baja ("Caja Negra"):** La clasificaci贸n se basa en la proximidad local; no hay reglas expl铆citas. |
| **Frontera de Decisi贸n** | Genera fronteras **rectas** (umbrales) y perpendiculares. | Genera fronteras **irregulares y curvas**, adapt谩ndose a la forma del vecindario. |
| **Velocidad de Predicci贸n** | **Muy r谩pida** (solo sigue unas pocas ramas). | **Lenta** (debe calcular la distancia a todos los puntos de entrenamiento en tiempo de predicci贸n). |

An谩lisis y conclusi贸n final:

1. Evaluaci贸n Cuantitativa (F1-Score y Recall):

El modelo K-NN (0.96) obtuvo una precisi贸n ligeramente superior al rbol de Decisi贸n (0.95). Sin embargo, en un problema m茅dico, la m茅trica m谩s cr铆tica no es la precisi贸n general, sino el Recall de la Clase Maligna (Clase 1), ya que busca minimizar los Falsos Negativos (no detectar un c谩ncer real).

Recall (Clase 1 - Maligno): K-NN obtuvo un Recall del 0.97 (97%), mientras que el rbol de Decisi贸n obtuvo un 0.96 (96%).

Conclusi贸n de M茅tricas: K-NN demostr贸 una capacidad de detecci贸n marginalmente superior para identificar correctamente los tumores malignos dentro de la muestra de prueba, lo que lo convierte en el modelo con mejor rendimiento puro.

2. La M茅trica Cr铆tica y el Impacto Cl铆nico (An谩lisis de la matriz):

La ventaja de K-NN en el Recall (97% vs 96%) significa que, aunque la diferencia es peque帽a, es m谩s eficaz para evitar el error m谩s costoso: un Falso Negativo. De 100 casos malignos, el K-NN predice 97 correctamente, dejando solo 3 Falsos Negativos, mientras que el rbol de Decisi贸n dejar铆a 4. En el diagn贸stico de c谩ncer, la prioridad absoluta es la sensibilidad, lo que favorece a K-NN en t茅rminos de rendimiento puro.

3. Balance entre Rendimiento e Interpretabilidad (Recomendaci贸n Final):

A pesar de que K-NN ofrece el mejor rendimiento estad铆stico y es el modelo preferido si solo consideramos la tasa de error:

Recomendaci贸n: Para una implementaci贸n en un entorno real, el rbol de Decisi贸n es a menudo el modelo recomendado. Su principal fortaleza es la alta interpretabilidad. La capacidad de proporcionar reglas claras y l贸gicas para un diagn贸stico ("Maligno porque el radio promedio es mayor a X") genera mayor confianza y es esencial para la validaci贸n cl铆nica por parte de un m茅dico.
